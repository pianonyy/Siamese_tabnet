{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "import os\n",
    "import wget\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/pianonyy/VCR_uplift.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -e VCR_uplift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для уменьшения объёма датасета за счёт изменения типов\n",
    "def reduce_mem_usage(df, verbose=True): \n",
    "    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-25 01:48:07,497] __main__                  INFO     Loading features...\n",
      "[2021-02-25 01:48:07,909] __main__                  INFO     Features are loaded\n",
      "[2021-02-25 01:48:07,910] __main__                  INFO     Features shape: (400162, 334)\n",
      "[2021-02-25 01:48:07,911] __main__                  INFO     Preparing data sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 255.69 Mb (68.1% reduction)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-25 01:48:51,311] __main__                  INFO     Data sets prepared\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "log_format = '[%(asctime)s] %(name)-25s %(levelname)-8s %(message)s'\n",
    "logging.basicConfig(\n",
    "    format=log_format,\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from load_and_prepare import (\n",
    "    prepare_clients,\n",
    "    prepare_products,\n",
    "    prepare_purchases,\n",
    "    load_train,\n",
    "    load_test,\n",
    ")\n",
    "\n",
    "\n",
    "from config import RANDOM_STATE, SUBMISSIONS_PATH\n",
    "logger.info('Loading features...')\n",
    "with open('features.pkl', 'rb') as f:\n",
    "    features: pd.DataFrame = pickle.load(f)\n",
    "logger.info('Features are loaded')\n",
    "\n",
    "logger.info(f'Features shape: {features.shape}')\n",
    "\n",
    "logger.info('Preparing data sets...')\n",
    "features.set_index('client_id', inplace=True)\n",
    "\n",
    "features = reduce_mem_usage(features)\n",
    "\n",
    "\n",
    "features = features.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "train = load_train()\n",
    "test = load_test()\n",
    "indices_train = train.index\n",
    "indices_test = test.index\n",
    "\n",
    "X_train = features.loc[indices_train, :]\n",
    "treatment_train = train.loc[indices_train, 'treatment_flg'].values\n",
    "target_train = train.loc[indices_train, 'target'].values\n",
    "# y_valid = make_z(treatment_train, target_train)\n",
    "\n",
    "X_test = features.loc[indices_test, :]\n",
    "\n",
    "RANDOM_STATE = 12\n",
    "\n",
    "indices_learn, indices_valid = train_test_split(\n",
    "    train.index,\n",
    "    test_size=0.3,\n",
    "    random_state=RANDOM_STATE + 1,\n",
    ")\n",
    "\n",
    "X_learn = features.loc[indices_learn, :]\n",
    "treatment_learn = train.loc[indices_learn, 'treatment_flg'].values\n",
    "target_learn = train.loc[indices_learn, 'target'].values\n",
    "# y_learn = make_z(treatment_learn, target_learn)\n",
    "\n",
    "X_valid = features.loc[indices_valid, :]\n",
    "treatment_valid = train.loc[indices_valid, 'treatment_flg'].values\n",
    "target_valid = train.loc[indices_valid, 'target'].values\n",
    "# y_valid = make_z(treatment_valid, target_valid)\n",
    "logger.info('Data sets prepared')\n",
    "\n",
    "# eval_set = [(np.column_stack((X_valid,treatment_valid)), target_valid)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = TabNetClassifier()\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabNetClassifier(n_d=8, n_a=8, n_steps=3, gamma=1.3, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=1, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=None, scheduler_params={}, mask_type='sparsemax', input_dim=None, output_dim=None, device_name='auto')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60011, 333)\n"
     ]
    }
   ],
   "source": [
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 1.61136 |  0:02:01s\n",
      "epoch 1  | loss: 1.5867  |  0:04:01s\n",
      "epoch 2  | loss: 1.57931 |  0:06:16s\n",
      "epoch 3  | loss: 1.5734  |  0:08:15s\n",
      "epoch 4  | loss: 1.57665 |  0:10:29s\n",
      "epoch 5  | loss: 1.57731 |  0:12:45s\n",
      "epoch 6  | loss: 1.57601 |  0:14:47s\n",
      "epoch 7  | loss: 1.57814 |  0:16:45s\n",
      "epoch 8  | loss: 1.5808  |  0:19:02s\n",
      "epoch 9  | loss: 1.57564 |  0:21:30s\n"
     ]
    }
   ],
   "source": [
    "T_train = treatment_learn\n",
    "\n",
    "\n",
    "# print(X_learn.shape)\n",
    "# print(T_train.shape)\n",
    "# print(target_learn.shape)\n",
    "\n",
    "\n",
    "\n",
    "clf.fit(\n",
    "    X_train=X_learn.values,T_train=T_train, y_train=target_learn,\n",
    "#     eval_set=[(X_learn, T_train, target_learn)],\n",
    "#     eval_name=['train'],\n",
    "#     eval_metric=['auc'],\n",
    "    max_epochs=10 , patience=20,batch_size=8573,\n",
    "\n",
    "    num_workers=0,\n",
    "    weights=1,\n",
    "    drop_last=False\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8573])\n",
      "torch.Size([8573])\n",
      "torch.Size([8573])\n",
      "torch.Size([8573])\n",
      "torch.Size([8573])\n",
      "torch.Size([8573])\n",
      "torch.Size([8573])\n",
      "[[ 2.27187574e-03 -9.75102186e-04 -4.27961349e-03 ...  1.26665831e-03\n",
      "  -8.98659229e-04  0.00000000e+00]\n",
      " [-1.55508518e-04  9.53200459e-03  8.69047642e-03 ... -1.56462193e-04\n",
      "  -1.31529570e-03 -6.95466995e-04]\n",
      " [-1.32936239e-03  5.12838364e-04 -3.96585464e-03 ...  9.19494033e-02\n",
      "   3.98688912e-02  4.38457727e-03]\n",
      " ...\n",
      " [ 5.87695837e-03  2.24673748e-03 -3.42264771e-03 ... -4.06968594e-03\n",
      "  -2.77078152e-03  1.33920372e-01]\n",
      " [ 1.26067400e-02 -9.79834795e-03  1.12593174e-04 ...  1.13189220e-03\n",
      "   9.24453139e-04  1.93595886e-04]\n",
      " [ 1.27652287e-02  1.93535089e-02  1.84084773e-02 ...  5.46997786e-02\n",
      "  -1.31040812e-04  8.12250376e-03]]\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict_proba(X_valid.values)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00227188]\n",
      " [-0.0009751 ]\n",
      " [-0.00427961]\n",
      " ...\n",
      " [ 0.05469978]\n",
      " [-0.00013104]\n",
      " [ 0.0081225 ]]\n"
     ]
    }
   ],
   "source": [
    "print(preds.reshape(60011,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\work\\ml_in_trading\\uplift_modeling_lib\\uplift\\metrics\\ranking.py:199: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "c:\\python38\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from uplift.metrics import uplift_at_k\n",
    "from uplift.metrics import qini_auc_score\n",
    "pred_uplift = preds[:,0]\n",
    " \n",
    "print(uplift_at_k(target_valid, preds.reshape(60011,1), treatment_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8573])\n",
      "torch.Size([8573])\n",
      "torch.Size([8573])\n",
      "torch.Size([8573])\n",
      "torch.Size([8573])\n",
      "torch.Size([8573])\n",
      "torch.Size([8573])\n",
      "[[ 2.27187574e-03 -9.75102186e-04 -4.27961349e-03 ...  1.26665831e-03\n",
      "  -8.98659229e-04  0.00000000e+00]\n",
      " [-1.55508518e-04  9.53200459e-03  8.69047642e-03 ... -1.56462193e-04\n",
      "  -1.31529570e-03 -6.95466995e-04]\n",
      " [-1.32936239e-03  5.12838364e-04 -3.96585464e-03 ...  9.19494033e-02\n",
      "   3.98688912e-02  4.38457727e-03]\n",
      " ...\n",
      " [ 5.87695837e-03  2.24673748e-03 -3.42264771e-03 ... -4.06968594e-03\n",
      "  -2.77078152e-03  1.33920372e-01]\n",
      " [ 1.26067400e-02 -9.79834795e-03  1.12593174e-04 ...  1.13189220e-03\n",
      "   9.24453139e-04  1.93595886e-04]\n",
      " [ 1.27652287e-02  1.93535089e-02  1.84084773e-02 ...  5.46997786e-02\n",
      "  -1.31040812e-04  8.12250376e-03]]\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict_proba(X_valid.values)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-85e0272eb9d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mT_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m clf.fit(\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mT_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mT_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0meval_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "T_train = np.random.randint(2, size=X_train.shape[0])\n",
    "clf.fit(\n",
    "    X_train=X_train,T_train=T_train, y_train=y_train,\n",
    "    eval_set=[(X_train, T_train, y_train)],\n",
    "    eval_name=['train'],\n",
    "    eval_metric=['auc'],\n",
    "    max_epochs=10 , patience=20,\n",
    "\n",
    "    num_workers=0,\n",
    "    weights=1,\n",
    "    drop_last=False\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "plt.plot(clf.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot auc\n",
    "plt.plot(clf.history['train_auc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning rates\n",
    "plt.plot(clf.history['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(X_test)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds[:,1]-preds[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(X_test)\n",
    "test_auc = roc_auc_score(y_score=preds[:,1], y_true=y_test)\n",
    "\n",
    "\n",
    "preds_valid = clf.predict_proba(X_valid)\n",
    "valid_auc = roc_auc_score(y_score=preds_valid[:,1], y_true=y_valid)\n",
    "\n",
    "print(f\"BEST VALID SCORE FOR {dataset_name} : {clf.best_cost}\")\n",
    "print(f\"FINAL TEST SCORE FOR {dataset_name} : {test_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that best weights are used\n",
    "assert np.isclose(valid_auc, np.max(clf.history['valid_auc']), atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tabnet model\n",
    "saving_path_name = \"./tabnet_model_test_1\"\n",
    "saved_filepath = clf.save_model(saving_path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define new model with basic parameters and load state dict weights\n",
    "loaded_clf = TabNetClassifier()\n",
    "loaded_clf.load_model(saved_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_preds = loaded_clf.predict_proba(X_test)\n",
    "loaded_test_auc = roc_auc_score(y_score=loaded_preds[:,1], y_true=y_test)\n",
    "\n",
    "print(f\"FINAL TEST SCORE FOR {dataset_name} : {loaded_test_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(test_auc == loaded_test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global explainability : feat importance summing to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local explainability and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_matrix, masks = clf.explain(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20,20))\n",
    "\n",
    "for i in range(3):\n",
    "    axs[i].imshow(masks[i][:50])\n",
    "    axs[i].set_title(f\"mask {i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf_xgb = XGBClassifier(max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=1000,\n",
    "    verbosity=0,\n",
    "    silent=None,\n",
    "    objective='binary:logistic',\n",
    "    booster='gbtree',\n",
    "    n_jobs=-1,\n",
    "    nthread=None,\n",
    "    gamma=0,\n",
    "    min_child_weight=1,\n",
    "    max_delta_step=0,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=1,\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    base_score=0.5,\n",
    "    random_state=0,\n",
    "    seed=None,)\n",
    "\n",
    "clf_xgb.fit(X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        early_stopping_rounds=40,\n",
    "        verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array(clf_xgb.predict_proba(X_valid))\n",
    "valid_auc = roc_auc_score(y_score=preds[:,1], y_true=y_valid)\n",
    "print(valid_auc)\n",
    "\n",
    "preds = np.array(clf_xgb.predict_proba(X_test))\n",
    "test_auc = roc_auc_score(y_score=preds[:,1], y_true=y_test)\n",
    "print(test_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}